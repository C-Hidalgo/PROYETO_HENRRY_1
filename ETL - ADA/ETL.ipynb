{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>STEAM GAMES</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de DataSet steam_games\n",
    "steam_games=pd.read_json('../Datasets/steam_games.json.gz',compression='gzip',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Elimina las filas donde todos sus valores son nulos\n",
    "steam_games.dropna(how='all',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proceso de Limpieza Columna 'id'\n",
    "steam_games[steam_games['id'].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games[steam_games['title'] == 'Batman: Arkham City - Game of the Year Edition'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se puede observar que se encontraron dos filas con id nuelos.\n",
    "#El primero carece de gran parte de su informacion, por tanto sera eliminada.\n",
    "#El segundo se puede concluir que se trata de una fila duplicada donde una de \n",
    "#esta no tiene el id, por lo que sera eliminada\n",
    "\n",
    "steam_games.dropna(subset=['id'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Busqueda de duplicados\n",
    "duplicates = steam_games[steam_games.duplicated(subset=['id'], keep=False)]\n",
    "print(duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se puede observar dos filas duplicada, por tanto se elimina una de estas\n",
    "steam_games.drop_duplicates(subset=['id'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir los valores de la columna 'id' en enteros\n",
    "steam_games['id'] = steam_games['id'].astype(int)\n",
    "steam_games.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proceso de Limpieza Columna 'app_name'\n",
    "\n",
    "#Busqueda de app_name nulos\n",
    "steam_games[steam_games['app_name'].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se encontro una appe_nume nula la cual carece de otras informaciones imnportantes,\n",
    "# por lo que sera eliminada\n",
    "steam_games.dropna(subset=['app_name'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proceso de Limpieza Columna 'developer'\n",
    "#Se remplazara los nulos de developer por los de publisher\n",
    "steam_games['developer'].fillna(steam_games['publisher'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proceso de limpieza columna 'genres'\n",
    "#Los valores de tags son iguales a genres, cargare los fataltante de genres con tags, \n",
    "#y creo un conjunto (set) con totos valores unicos de genres.\n",
    "\n",
    "#Creando un conjunto ( set) que contiene todos los \n",
    "#géneros únicos presentes en la columna 'géneros' del DataFrame\n",
    "genres = set(item for val in steam_games['genres'].dropna() for item in val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrando las etiquetas 'tags' para mantener solo aquellas \n",
    "#que están presentes en 'genres'\n",
    "steam_games['tags'] = steam_games['tags'].apply(lambda x: [item for item in x if item in genres] if isinstance(x, list) else x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de valores nulos en la columna 'genres' con valores de 'tags'\n",
    "steam_games['genres'].fillna(steam_games['tags'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion que añade valores a 'geners' que estan en 'tags'\n",
    " #Función que añade valores de 'tags' a 'genres' que no estén ya presentes en 'genres'\n",
    "def agregar_genres(fila):\n",
    "    genres = fila['genres']\n",
    "    tags = fila['tags']\n",
    "    if isinstance(tags,list) and isinstance(genres,list):\n",
    "        for tag in tags:\n",
    "            if tag not in genres:\n",
    "                genres.append(tag)\n",
    "    return genres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando la función 'agregar_genres' a todos los elementos en el dataframe\n",
    "steam_games['genres'] = steam_games.apply(lambda fila: agregar_genres(fila), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion de columnas ficticias a travez d dumies con los valores de geners\n",
    "# Ahora voy a generar dummies para genres \n",
    "steam_games['genres'] =  steam_games['genres'].apply(lambda x:\".\".join(x) if isinstance(x, list) else x)\n",
    "dummies = steam_games['genres'].str.get_dummies(sep='.')\n",
    "dummies = dummies.groupby(dummies.columns, axis=1).sum()\n",
    "steam_games = pd.concat([steam_games,dummies],axis=1)\n",
    "steam_games.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Elimino todas las columnas inecesarias\n",
    "# publisher\n",
    "# genres\n",
    "# title\n",
    "# url\n",
    "# tags\n",
    "# discount_price\n",
    "# reviews_url\n",
    "# early_access\n",
    "# specs\n",
    "# price\n",
    "\n",
    "\n",
    "steam_games = steam_games.drop(columns=['publisher', 'genres', 'title', 'url', 'tags', 'reviews_url', 'early_access', 'specs', 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluacion de Porcentaje de nulos\n",
    "print(f'Porcentaje de nulos : {1 - steam_games.dropna(subset=[\"developer\",\"release_date\"]).shape[0] / steam_games.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entre las columnas release_date y developer hacen un 11% de valores nulos. al poder \n",
    "#hacer mas analisis y asignar valores, procedo a la eliminacion de dichas filas\n",
    "steam_games.dropna(subset=['developer','release_date'],inplace=True)\n",
    "steam_games.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(steam_games.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proceso de Limpieza Columna release_date\n",
    "steam_games['release_date'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifico el formato de los año usando re\n",
    "# Función para verificar el formato 'YYYY-MM-DD'\n",
    "def is_valid_date_format(date_str):\n",
    "    regex = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "    return re.match(regex, date_str) is not None\n",
    "\n",
    "# Crear una máscara booleana para las fechas que no tienen el formato 'YYYY-MM-DD'\n",
    "invalid_date_mask = ~steam_games['release_date'].astype(str).apply(is_valid_date_format)\n",
    "\n",
    "# Filtrar las filas con fechas que no tienen el formato 'YYYY-MM-DD'\n",
    "invalid_dates = steam_games[invalid_date_mask]\n",
    "\n",
    "# Mostrar las fechas que no tienen el formato 'YYYY-MM-DD'\n",
    "print(invalid_dates['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hago una funcion para tratar los valores que no tienen el formato YYYY-MM-DD\n",
    "def arreglar_errores(fecha: str):\n",
    "    try:\n",
    "        # Intenta convertir la fecha directamente a entero\n",
    "        return int(fecha)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # Intenta dividir la fecha usando un espacio en blanco como delimitador y convierte la segunda parte a entero\n",
    "            return int(fecha.split(\" \")[1])\n",
    "        except (IndexError, ValueError):\n",
    "            try:\n",
    "                # Intenta dividir la fecha usando \".\" como delimitador y convierte la tercera parte a entero\n",
    "                return int(fecha.split(\".\")[2])\n",
    "            except (IndexError, ValueError):\n",
    "                try:\n",
    "                    # Intenta dividir la fecha usando un espacio en blanco como delimitador y convierte la quinta parte a entero\n",
    "                    return int(fecha.split(\" \")[4])\n",
    "                except (IndexError, ValueError):\n",
    "                    # Si no se puede convertir, devuelve None\n",
    "                    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games.loc[invalid_date_mask, 'Year'] = steam_games.loc[invalid_date_mask, 'release_date'].apply(arreglar_errores)\n",
    "\n",
    "# Convertir las fechas válidas a datetime y extraer el año\n",
    "valid_date_mask = ~invalid_date_mask\n",
    "steam_games.loc[valid_date_mask, 'Year'] = pd.to_datetime(steam_games.loc[valid_date_mask, 'release_date'], errors='coerce').dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llevo la columna Year a formato int\n",
    "steam_games['Year'] = steam_games['Year'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(steam_games.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino la Columna 'release_date'\n",
    "steam_games.drop(columns=['release_date'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino las filas con valores vacio de la columna 'Year'\n",
    "steam_games['Year'].isnull().sum()\n",
    "steam_games['Year'].replace('', np.nan, inplace=True)\n",
    "steam_games.dropna(subset=['Year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elimino la columna developer\n",
    "steam_games = steam_games.drop(columns=['developer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trabajo con el 10% de la base de datos\n",
    "porcentaje_a_eliminar = 0.90\n",
    "\n",
    "# Calcula el número de filas a eliminar\n",
    "num_filas_a_eliminar = int(len(steam_games) * porcentaje_a_eliminar)\n",
    "\n",
    "# Utiliza el método sample para seleccionar aleatoriamente las filas a eliminar\n",
    "filas_a_eliminar = steam_games.sample(n=num_filas_a_eliminar, random_state=42)\n",
    "\n",
    "# Elimina las filas seleccionadas del DataFrame original\n",
    "steam_games = steam_games.drop(filas_a_eliminar.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games.to_csv('../Datasets/steam_games.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>USERS REVIEWS</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de DataSet Orignal\n",
    "user_reviews_gz = \"../Datasets/user_reviews.json.gz\"\n",
    "filas=[]\n",
    "with gzip.open(user_reviews_gz, 'rt', encoding='MacRoman') as archivo:\n",
    "    for line in archivo.readlines():\n",
    "        filas.append(ast.literal_eval(line))\n",
    "\n",
    "user_review = pd.DataFrame(filas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Datasets user_review contiene 3 columnas donde la 'reviews' es una lista de diccionario que contiene iformacion de los comentarios realizados en cada juego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "por consiguiente se procede al desanidado de la columna'reviews' repitiendo las filas del usuario para cada item_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode = user_review.explode('reviews') # Duplico las filas generando un diccionario por cada diccionario en la lista\n",
    "# Ahora concateno el dataframe original, con el dataframe generado a partir de transformar los diccionarios a pandas\n",
    "user_review_explode = pd.concat([user_review_explode.drop(['reviews'],axis=1),user_review_explode['reviews'].apply(pd.Series)],axis=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimino columnas que no seran usadas para el estudio\n",
    "* user_url\n",
    "* funny\n",
    "* last_edited\n",
    "* helpful\n",
    "* 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode.drop(columns=['user_url','funny','helpful','last_edited',0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> A partir de la columna reveiw se hara un analisis de sentimiento, generando una nueva columna.\n",
    " Este se llamara \"sentiment_analysis\"  y tendra 2 para sentimiento positivo 0 para negativo y 1 para neutral\n",
    " Habiendo hecho esto elimino la columna review </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hago el analisis de sentimiento en la columna review\n",
    "nltk.download('vader_lexicon')\n",
    "model_sentimiento = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def analizador(review):\n",
    "    # Obtener el puntaje de sentimiento usando SentimentIntensityAnalyzer\n",
    "    sentimiento_score = model_sentimiento.polarity_scores(review)\n",
    "    \n",
    "    # Clasifico el sentimiento\n",
    "    \n",
    "    if review and not pd.isnull(review):\n",
    "        if sentimiento_score['compound'] >= 0.5:\n",
    "            return 2  # Sentimiento positivo\n",
    "        elif sentimiento_score['compound'] <= -0.5:\n",
    "            return 0  # Sentimiento negativo\n",
    "        else:\n",
    "            return 1  # Sentimiento neutral\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para aplicar la funcion los nulos tienen que ser vacio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode['review'].fillna('',inplace=True) # Remplazo los nulos con un string vacio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode['sentiment_analysis']  = user_review_explode['review'].apply(analizador)\n",
    "user_review_explode.drop(columns='review',inplace=True) # Aplica la funcion que determina el sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Grafico las el analisis por sentimiento de las reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='sentiment_analysis', data=user_review_explode)\n",
    "plt.title('Violinplot de Análisis de Sentimientos')\n",
    "plt.xlabel('Puntuación de Sentimiento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestro la Cantidad de nulos por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode[user_review_explode.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan las filas nulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trabajo con el 10% de la base de datos\n",
    "porcentaje_a_eliminar = 0.90\n",
    "\n",
    "# Calcula el número de filas a eliminar\n",
    "num_filas_a_eliminar = int(len(user_review_explode) * porcentaje_a_eliminar)\n",
    "\n",
    "# Utiliza el método sample para seleccionar aleatoriamente las filas a eliminar\n",
    "filas_a_eliminar = user_review_explode.sample(n=num_filas_a_eliminar, random_state=42)\n",
    "\n",
    "# Elimina las filas seleccionadas del DataFrame original\n",
    "user_review_explode = user_review_explode.drop(filas_a_eliminar.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporta como csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode.to_csv('../datasets/user_reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> USERS ITEMS </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descomprimo el dataset de items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descompimir_json(ruta, variable_anidada):\n",
    "    '''Función que recibe una ruta de acceso a un archivo json anidado y carga la información en un\n",
    "    DataFrame de Pandas'''\n",
    "    fila = []\n",
    "    with gzip.open(ruta, 'rt', encoding='MacRoman') as archivo:\n",
    "      for line in archivo.readlines():\n",
    "          fila.append(ast.literal_eval(line))\n",
    "\n",
    "    df = pd.DataFrame(fila)                                                 \n",
    "    df = df.explode(variable_anidada).reset_index()                         \n",
    "    df = df.drop(columns=\"index\")                                           \n",
    "    df = pd.concat([df, pd.json_normalize(df[variable_anidada])], axis=1)   \n",
    "    df = df.drop(columns=variable_anidada)                                  \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items = descompimir_json(\"../datasets/users_items.json.gz\",'items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items[users_items['item_id'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los nulos hacen referencia a las mismas filas por esto seran eliminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por ultimo elimino las columnas que no usare\n",
    "* user_url\n",
    "* playtime_2weeks\n",
    "* steam_id\n",
    "* item_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items.drop(columns=['user_url','playtime_2weeks','steam_id', 'item_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=users_items,y='playtime_forever') # Hago un diagrama de caja para ver outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiene muchos outliers, pero si se consideran minutos no tienen que ser necesariamente errores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporto el dataframe a csv y lo comprimo en gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items.to_csv('../datasets/users_items.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trabajo con el 10% de la base de datos\n",
    "porcentaje_a_eliminar = 0.90\n",
    "\n",
    "# Calcula el número de filas a eliminar\n",
    "num_filas_a_eliminar = int(len(users_items) * porcentaje_a_eliminar)\n",
    "\n",
    "# Utiliza el método sample para seleccionar aleatoriamente las filas a eliminar\n",
    "filas_a_eliminar = users_items.sample(n=num_filas_a_eliminar, random_state=42)\n",
    "\n",
    "# Elimina las filas seleccionadas del DataFrame original\n",
    "users_items = users_items.drop(filas_a_eliminar.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items.to_csv('../datasets/users_items.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../datasets/users_items_project.csv.gz', 'wb') as f:\n",
    "    users_items.to_csv(f, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
